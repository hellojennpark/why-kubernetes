# etcd

etcd는 쿠버네티스 클러스터의 **모든 상태**를 저장하는 **분산 키-값 저장소**입니다.

그렇다면 '상태'란 무엇이고, 왜 etcd라는 분산 키-값 저장소를 사용하는 걸까요? 이제부터 알아보겠습니다.

## '상태'의 의미

쿠버네티스에서 **상태(State)**&#xB294; 단순히 pod가 'Running'인지 아닌지 같은 런타임 정보만을 뜻하지 않습니다. 클러스터를 구성하고 동작시키는 모든 오브젝트의 스펙(spec)과 현재 상황이 포함됩니다.

| etcd가 보관하는 주요 상태 범주 | 구체적 예시(오브젝트)                                                             | 설명                                                      |
| ------------------- | ------------------------------------------------------------------------ | ------------------------------------------------------- |
| **워크로드 리소스**        | Pods, Deployments, ReplicaSets, StatefulSets, DaemonSets, Jobs, CronJobs | 어떤 애플리케이션을 몇 개의 인스턴스로, 어떤 설정으로 실행해야 하는지                 |
| **서비스 및 네트워크**      | Services, Endpoints, Ingress, NetworkPolicy                              | 서비스 이름과 IP 매핑, 로드밸런싱 규칙, 네트워크 통신 정책                     |
| **구성/비밀 관리**        | ConfigMaps, Secrets                                                      | 앱이 사용할 설정 값, 민감한 데이터(비밀번호, API 키 등)                     |
| **스토리지 관련**         | PersistentVolume(PV), PersistentVolumeClaim(PVC), StorageClass           | 상태 저장 서비스가 사용하는 볼륨 및 스토리지 정책                            |
| **보안/권한**           | ServiceAccounts, Roles, RoleBindings, ClusterRoles                       | 인증/인가 설정, RBAC(Role-Based Access Control) 정책            |
| **클러스터 메타데이터**      | Nodes, Namespaces, ResourceQuotas, LimitRanges                           | 노드 등록 정보, 네임스페이스 단위의 리소스 제한                             |
| **상태(Status) 정보**   | 각 리소스의 현재 상태 필드 (`status` section)                                       | 파드의 현재 Phase(Running, Pending), 노드의 Ready 여부 등 현재 동작 상황 |

<p align="center"><sup>[표] etcd가 보관하는 주요 상태 범주</sup></p>

## **오브젝트 의미**

**오브젝트(Object)**&#xB294; 쿠버네티스가 관리해야 하는 실제 리소스를 표현하는 단위입니다. 클러스터 안에서 '무엇을 만들고 유지할지'를 나타내는 기록이라고 볼 수 있습니다. &#x20;

오브젝트 안에 있는 원하는 상태(Desired State)를 기술하는 부분을 **스펙(spec)**&#xC774;라고 부릅니다. 사용자가 '이 오브젝트가 이렇게 동작해야 한다'라고 선언적으로 적어두는 설정입니다.

| 오브젝트                                     | 설명                         |
| ---------------------------------------- | -------------------------- |
| Pod                                      | 컨테이너 실행 단위                 |
| Service                                  | 파드를 묶어 네트워크로 접근 가능하게 하는 단위 |
| Deployment                               | 파드의 수, 업데이트 전략 등을 관리하는 단위  |
| ConfigMap / Secre                        | 설정 값이나 비밀 정보 저장            |
| PersistentVolume / PersistentVolumeClaim | 스토리지 볼륨과 그 사용 요청           |
| Namespace                                | 리소스를 구분하는 논리적 영역           |

<p align="center"><sup>[표] 주요 오브젝트 종류</sup></p>

## etcd를 사용하는 이유

### 1. 단일 진실 저장소 (Single Source of Truth)

쿠버네티스는 수많은 컴포넌트(API Server, Scheduler, Controller Manager, kubelet 등)가 동시에 같은 데이터를 읽고 써야 합니다. 이때 **어느 컴포넌트가 봐도 동일한, 신뢰할 수 있는 단일 데이터 원본**이 필요합니다.

etcd는 Raft 합의 알고리즘을 사용해 **모든 노드에 동일한 데이터를 복제**하고, 어느 노드에서 읽더라도 항상 일관된 데이터를 보장합니다.

{% hint style="info" %}
**Raft 합의(Consensus) 알고리즘**은 여러 대의 컴퓨터(노드)가 네트워크로 묶인 **분산 시스템**에서 모두가 **동일한 데이터 값을 신뢰할 수 있도록 합의(Consensus)를 이루는 방법**입니다. 쿠버네티스의 etcd가 이 알고리즘을 사용해 “클러스터 상태”를 안전하게 저장하고 복제합니다.
{% endhint %}

### 2. Desired State와 Current State를 비교·유지하기 위해

쿠버네티스의 핵심 아이디어는 “원하는 상태(Desired State)를 선언하면, 컨트롤러가 실제 상태(Current State)를 그에 맞추어 유지한다”입니다.

* 사용자가 Deployment 매니페스트로 `replicas: 3`을 선언하면 이 정보가 etcd에 기록됩니다.
* Controller Manager는 etcd에 기록된 **spec**(원하는 상태)과 kubelet이 보고하는 **status**(현재 상태)를 비교합니다.
* 차이가 있으면 Scheduler·kubelet 등을 통해 새 파드를 띄우거나 장애 노드에서 파드를 다른 노드로 옮겨 원하는 상태를 맞춥니다.

즉, etcd가 **Desired/Current 상태를 모두 보관하는 단일 데이터베이스**이기 때문에 컨트롤 플레인이 이 차이를 실시간으로 감지하고 조정할 수 있습니다.

### 3. 고가용성(HA)과 내결함성(FT)

{% hint style="info" %}
* **고가용성(High Availability, HA)** 은 시스템이나 서비스가 장애나 유지보수 같은 상황에서도 **장시간 중단 없이 지속적으로 사용 가능한 상태를 유지하는 능력**을 말합니다.
* **내결함성(Fault Tolerance)** 은 시스템의 일부 구성 요소가 **고장(Fault)** 나더라도 전체 서비스가 중단되지 않고 **정상적으로 동작을 계속할 수 있는 능력**을 말합니다.
{% endhint %}

쿠버네티스 클러스터는 수백, 수천 개의 노드에서 운영될 수 있고 부분 장애가 일상적으로 발생할 수 있습니다.\
etcd는 Raft 합의 알고리즘을 통해 **다중 노드에 상태를 복제**하여 한 노드가 다운되더라도 데이터가 유실되지 않게 합니다.

이 특성 덕분에 쿠버네티스는 **컨트롤 플레인의 장애 복구**나 **클러스터 재시작** 시에도 원하는 상태를 잃지 않고, 운영을 이어갈 수 있습니다.



내결함성, 즉 클러스터가 데이터 손실 없이 **동시에 허용할 수 있는 최대 장애 노드 수**($$F$$)는 전체 멤버 수($$N$$)와 쿼럼 규칙에 의해 결정됩니다.

<p align="center"><span class="math">F = (N-1)/2</span></p>

이는 곧 $$N$$개의 멤버로 구성된 클러스터는 $$F$$개의 노드 장애를 허용하며, $$F+1$$개 이상의 노드에 장애가 발생하면 쿼럼이 깨져 클러스터 전체가 **쓰기 작업을 중단(Stall)**&#xD558;고 비활성화된다는 의미입니다.

{% hint style="info" %}
분산 합의 알고리즘(쿠버네티스의 etcd가 쓰는 **Raft**)에서는 **“다수 노드가 동일한 결정을 내려야만 데이터 변경을 확정(Commit)”** 할 수 있습니다.  이때 변경을 승인하는 데 필요한 **최소한의 동의 수**를 **Quorum(정족수)** 라고 합니다.
{% endhint %}

etcd 클러스터는 내결함성을 극대화하고 쿼럼 형성을 명확하게 하기 위해 반드시 홀수로 구성해야 합니다.

| Cluster Size(멤버 수) | Majority(쿼럼, 과반수) | Failure Tolerance(허용 가능한 최대 장애 수) |
| ------------------ | ----------------- | --------------------------------- |
| 1                  | 1                 | 0                                 |
| 2                  | 2                 | 0                                 |
| 3                  | 2                 | 1                                 |
| 4                  | 3                 | 1                                 |
| 5                  | 3                 | 2                                 |
| 6                  | 4                 | 2                                 |
| 7                  | 4                 | 3                                 |
| 8                  | 5                 | 3                                 |
| 9                  | 5                 | 4                                 |

<p align="center"><sup>[표] 멤버 수와 허용 가능한 최대 장애 수</sup></p>

### 4. 트랜잭션과 변경 이력

etcd는 **원자적 트랜잭션**과 **변경 이력(revision history)** 기능을 제공합니다.&#x20;

{% hint style="info" %}
**원자적 트랜잭션**은 데이터베이스에서 한 번의 작업 단위(트랜잭션) 안의 모든 연산이 **모두 성공하거나, 아예 아무 것도 적용되지 않도록** 보장하는 성질을 말합니다.

* **데이터 일관성 유지**: 중간 단계에서 일부만 적용되면 데이터가 꼬일 수 있습니다.
* **장애 복구**: 작업 도중 네트워크가 끊기거나 노드가 고장 나도, 트랜잭션 전체가 취소되면 시스템이 안전한 상태를 유지할 수 있습니다.
* **분산 환경 안정성**: etcd나 쿠버네티스처럼 여러 노드가 동시에 데이터를 쓰는 환경에서, “반쯤 기록된 값”이 남지 않게 보장합니다.

etcd는 Raft 합의 알고리즘을 사용해 키-값 변경을 트랜잭션 단위로 커밋합니다. 파드 스케일링을 3→5로 늘리는 도중 일부 노드에만 반영되고 다른 노드가 실패한다면, 클러스터 전체 상태가 뒤죽박죽될 수 있습니다. 원자적 트랜잭션이 이를 방지해 “모두 성공” 혹은 “모두 실패”로 일관성을 보장합니다.
{% endhint %}

Controller나 API Server는 특정 리비전 이후의 변화만 감지해 효율적으로 동작할 수 있습니다. 또한 watch 기능을 통해 **변경 이벤트를 실시간으로 구독**할 수 있어, 컨트롤러들이 즉각적으로 반응할 수 있습니다.

{% hint style="info" %}
변경이력은 분산 키-값 저장소(etcd 등)에서 각 데이터 변경 시점마다 **리비전(Revision) 번호**를 부여하고,\
과거의 변경 기록을 조회하거나, 특정 시점 이후의 변화만 추적할 수 있게 하는 기능입니다.

* **이벤트 구독(Watches)**: 컨트롤러가 “이 리비전 이후의 변경만” 실시간으로 감지해 빠르게 반응할 수 있습니다.
* **롤백·디버깅**: 과거 상태를 재현하거나, 어떤 변경이 장애를 유발했는지 추적할 수 있습니다.
* **동시성 제어**: 클라이언트가 특정 리비전을 기준으로 조건부 업데이트를 수행해 경쟁 상태(race condition)를 방지할 수 있습니다.
{% endhint %}

## [**Raft 합의(Consensus)**](https://raft.github.io/) **알고리즘**

etcd를 사용하는 이유에서 언급 했듯이 etcd는 클러스터의 상태를 안전하게 저장하고 복제하기 위해 Raft 합의 알고리즘을 사용합니다. 여기서 **합의(Consensus)** 는 분산 시스템에서 **여러 노드가 동일한 “정답”을 선택하거나 동일한 상태를 공유하기로 동의하는 과정**을 말합니다. 조금 더 자세히 알아보겠습니다.

### 1. 왜 합의(Consensus)가 필요한가

분산 시스템에서는 데이터가 여러 노드에 복제돼 있습니다.

이 중 한두 대가 고장나거나 네트워크가 일시적으로 끊기더라도, 전체 시스템이 **어떤 값을 “진짜 값”으로 인정할지 모두가 같은 결론**을 내려야 합니다. 이 결론을 내리는 절차가 **합의**입니다.

예를 들어,

* 한 노드가 잠깐 통신이 끊겼다가 다시 연결될 수 있고,
* 어떤 노드는 최신 데이터를 받지 못했을 수도 있습니다.

이때 모든 노드가 **서로 다른 값을 저장**한다면, “진짜 데이터가 무엇인지”를 결정할 방법이 필요합니다.\
이 문제를 **합의 문제(Consensus Problem)**&#xB77C;고 합니다.

### 2. Raft의 핵심 아이디어

Raft 합의 알고리즘은 이런 **합의를 달성하는 구체적 방법**입니다.

| 요소                | 역할                               |
| ----------------- | -------------------------------- |
| **리더(Leader)**    | 클러스터에서 단 한 대가 선출되어 모든 쓰기 작업을 총괄  |
| **팔로워(Follower)** | 리더가 보낸 로그를 받아 복제                 |
| **후보(Candidate)** | 리더가 실패했을 때 새 리더가 되기 위해 선출 과정에 참여 |

<p align="center"><sup>[표] 주요 구성 요소</sup></p>

### 3. 동작 과정

1. **리더 선출(Leader Election)**
   * 클러스터가 시작되면 노드들은 투표를 통해 한 대를 리더로 선출합니다.
   * 리더가 다운되면 일정 시간(선거 타임아웃) 후 팔로워가 Candidate가 되어 새 리더를 뽑습니다.
2. **로그 복제(Log Replication)**
   * 모든 쓰기 요청(데이터 변경)은 리더를 통해서만 수행됩니다.
   * 리더가 변경 내용을 “로그 항목(log entry)”로 팔로워들에게 전송합니다.
3. **다수결 동의(Majority Agreement)**
   * 팔로워 다수가 이 로그를 안전히 저장하면(다수결), 리더가 커밋(Commit)했다고 선언하고\
     그 시점에 데이터가 확정됩니다.

이렇게 하면 다수의 노드가 동일한 로그 순서를 공유하므로, 리더가 바뀌거나 일부 노드가 장애를 일으켜도 이미 커밋된 데이터는 절대 뒤바뀌지 않습니다.

### 4. 장애 상황에서의 동작 시나리오

* **노드 장애**
  * 예: 3노드 etcd 클러스터에서 한 노드가 다운되더라도,\
    나머지 2노드가 과반수(majority)이기 때문에 합의된 상태가 유지됩니다.
  * API Server는 남은 정상 노드들에서 동일한 값을 읽을 수 있습니다.
* **네트워크 단절**
  * 일부 노드가 일시적으로 통신 불가 상태가 되더라도,\
    과반수 노드가 서로 통신 가능하면 리더가 유지되고 쓰기 작업이 정상 처리됩니다.
  * 단절된 노드가 복구되면, 아직 커밋되지 않은 로그를 리더로부터 동기화 받아 최신 상태로 맞춥니다.
* **리더 장애**
  * 리더가 죽으면 일정 타임아웃 후 팔로워 중 하나가 **새 리더**로 선출됩니다.
  * 그동안 읽기 요청은 팔로워가 처리하고, 쓰기 요청은 새 리더 선출 후 재개됩니다.

이처럼 Raft 합의 알고리즘은 **일부 노드가 장애를 일으키거나 네트워크가 일시적으로 분리돼도** 클러스터 전체가 **동일한 로그 순서와 데이터 값**을 공유하도록 보장합니다. 합의가 끝난 데이터는 리더가 교체되더라도 뒤바뀌지 않기 때문에 쿠버네티스의 etcd는 **일관성(consistency)** 과 **고가용성(High Availability)** 을 동시에 확보할 수 있습니다.

결국 Raft를 통해 etcd는 “신뢰할 수 있는 단일 상태 저장소(Single Source of Truth)” 역할을 안정적으로 수행하며, 쿠버네티스가 **사용자가 선언한 원하는 상태(Desired State)** 를 장애 상황에서도 지속적으로 유지할 수 있게 됩니다.

## [백업](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster)

앞서 설명했듯이, etcd는 쿠버네티스 클러스터의 모든 설정, 상태, 메타데이터를 저장하는 **'단 하나의 진실의 원천(Single Source of Truth)'**&#xC785;니다.  쿠버네티스에서 '모든 것'은 etcd에 저장된 데이터를 기반으로 작동합니다.

그렇다면 etcd 데이터가 손상되거나 유실되었을 때 어떤 일이 일어날까요? 컨트롤 플레인은 자신이 무엇을 해야 할지, 클러스터에 어떤 리소스가 존재하는지 완전히 잊어버리게 됩니다. 이는 곧 클러스터 전체의 다운으로 이어지며, 복구하기 위해서는 처음부터 모든 설정을 다시 수동으로 생성해야 하는 치명적인 상황을 초래합니다.

따라서 etcd를 정기적으로 백업하고, 재난 상황 발생 시 이를 이용해 **클러스터 상태를 복원(Restore)**&#xD558;는 것은 쿠버네티스 운영에서 가장 중요한 재해 복구(Disaster Recovery) 전략의 핵심입니다.

## HA 클러스터

기본적으로 쿠버네티스 클러스터를 설치하면 **컨트롤 플레인(Control Plane)**&#xC774; **단일 노드**에 위치하는 경우가 많습니다.이런 구성을 흔히 '싱글 컨트롤 플레인'이라고 부릅니다.

<figure><img src="../.gitbook/assets/image (10).png" alt="" width="188"><figcaption></figcaption></figure>

{% hint style="info" %}
컨트롤 플레인의 핵심 구성 요소로는 kube-apiserver, controller-manager, kube-scheduler, **etcd**가 있습니다.
{% endhint %}

간단하게 구축할 수 있다는 장점이 있지만, 컨트롤 플레인 노드에서 장애(서버 다운, 네트워크 장애 등)이 발생하면 문제가 생기게 됩니다. API Server가 응답하지 않으니 새로운 파드를 만들거나 스케줄링하고 노드를 관리하는 모든 제어 기능이 중단되게 되는거죠. 이미 워커 노드 위에서 실행 중이던 파드들은 잠시 계속 동작할 수 있지만, 클러스터 전체를 관리하거나 새로운 리소스를 배포할 수 없게 됩니다.

이러한 위험을 줄이기 위해 **고가용성(High Availability, HA) 클러스터**를 구성합니다. HA 클러스터는 컨트롤 플레인 구성 요소를 여러 노드에 분산하고 복제해, 특정 노드가 고장 나더라도 나머지 노드가 제어 기능을 이어받도록 설계됩니다. 즉, 한 대의 컨트롤 플레인 노드에 문제가 생겨도 클러스터 전체가 중단되지 않고 정상적으로 제어와 운영을 계속할 수 있게 만드는 것이 HA 클러스터의 목적입니다.

| 구분         | 싱글 컨트롤 플레인            | HA 컨트롤 플레인                  |
| ---------- | --------------------- | --------------------------- |
| 컨트롤 플레인 노드 | 1대                    | 3대 이상(일반적으로 3\~5)           |
| etcd 노드    | 1대 (내장)               | 3대 이상 (stacked 또는 external) |
| 장애 허용      | 컨트롤 플레인 노드 장애 시 제어 불가 | 일부 노드가 다운돼도 서비스 지속          |
| 운영 복잡도     | 단순, 설치 빠름             | 설치·업그레이드·모니터링 더 복잡          |
| 권장 용도      | 테스트, 개발 환경            | 프로덕션 환경                     |

<p align="center"><sup>[표] 싱글 컨트롤 플레인과 HA 컨트롤 플레인의 차이</sup></p>

### [HA 토플로지](https://kubernetes.io/ko/docs/setup/production-environment/tools/kubeadm/ha-topology/)

쿠버네티스 문서에서 말하는 토폴로지(topology) 는 네트워크나 시스템을 어떻게 배치하고 서로 연결했는지를 가리키는 기술 용어입니다. 쉽게 말해 “구성도” 또는 “배치 구조”라고 생각하면 됩니다. 따라서 'HA topology'라고 하면 **컨트롤 플레인과 etcd를 어떤 식으로 배치하고 서로 연결할지**를 나타냅니다.

HA 토플로지는 아래 두가지 방식으로 구성할 수 있습니다.

* etcd 노드와 컨트롤 플레인 노드를 함께 위치시키는 **중첩된(stacked) 컨트롤 플레인 노드** 방식
* etcd와 컨트롤 플레인이 분리된 노드에서 운영되는 **외부 etcd 노드** 방식

하나씩 알아보도록 하겠습니다.

#### 중첩된 컨트롤 플레인 노드(Stacked Control Plane Nodes)

<figure><img src="../.gitbook/assets/image (11).png" alt="" width="375"><figcaption></figcaption></figure>

컨트롤 플레인 노드 각각에 etcd를 함께 배치하는 방식입니다. 각 컨트롤 플레인 노드는 지역 etcd 맴버를 생성하고 이 etcd 맴버는 오직 해당 노드의 kube-apiserver와 통신합니다.

컨트롤 플레인과 etcd 맴버가 같은 노드에 묶여 있어서 외부 etcd 노드의 클러스터를 구성하는 것보다는 단순하며 복제 관리도 간단합니다. 다만, 중첩된 클러스터는 커플링에 실패할 위험이 있습니다. 한 노드가 다운되면 etcd 맴버와 컨트롤 플레인을 모두 잃어버리고, 중복성도 손상되기 때문에 더 많은 컨트롤 플레인 노드를 추가하여 이 위험을 완화할 수 있습니다. 그러므로 HA 클러스터를 위해 **최소 3개**인 중첩된 컨트롤 플레인 노드를 운영해야 합니다.

{% hint style="info" %}
중첩된 컨트롤 플레인 노드는 kubeadm의 기본 토플로지입니다. 지역 etcd 맴버는 `kubeadm init`와 `kubeadm join --control-plane` 을 이용할 때에 컨트롤 플레인 노드에 자동으로 생성됩니다.
{% endhint %}

| 장점                                              | 단점                                                            |
| ----------------------------------------------- | ------------------------------------------------------------- |
| **구성 단순:** 컨트롤 플레인 노드를 늘리면 etcd도 함께 늘어나므로 관리 편리 | **리소스 경쟁:** 컨트롤 플레인 컴포넌트와 etcd가 동일 노드 자원을 공유 → 고부하 시 성능 저하 가능 |
| **리소스 효율:** 별도의 etcd 전용 노드가 필요 없음               | **장애 도메인 공유:** 노드 장애가 컨트롤 플레인과 etcd 둘 다에 동시에 영향을 줄 수 있음       |
| kubeadm 기본 설정이 이 방식을 지원하므로 구축이 비교적 쉬움           | 대규모 클러스터에서 etcd I/O 부하가 클 경우 성능 튜닝이 어려움                       |

<p align="center"><sup>[표] 중첩된 컨트롤 노드의 장단점</sup></p>

#### 외부 etcd 노드(External etcd Nodes)

<figure><img src="../.gitbook/assets/image (12).png" alt="" width="375"><figcaption></figcaption></figure>



etcd 클러스터를 전용 노드로 분리하여 운영하는 방식입니다. 중첩된 etcd 토플로지와 유사하게, 외부 etcd 토플로지에 각 컨트롤 플레인 노드는 `kube-apiserver`, `kube-scheduler`, `kube-controller-manager`의 인스턴스를 운영하고 `kube-apiserver`는 로드 밸런서를 이용하여 워커노드에 노출합니다. 그러나 **etcd 맴버는 분리된 호스트에서 운영**되고, 각 etcd 호스트는 각 컨트롤 플레인 노드의 `kube-apiserver`와 통신합니다.

{% hint style="info" %}
Separation of Concerns는 **서로 다른 기능을 가진 컴포넌트를 분리**해 각각을 독립적으로 관리·확장·보안 강화할 수 있게 하는 설계 원칙입니다.
{% endhint %}

컨트롤 플레인과 etcd 맴버를 분리하기 때문에 컨트롤 플레인 인스턴스나 etcd 맴버를 잃는 충격이 덜하고, 클러스터 중복성에 있어 중첩된 HA 토플로지만큼 영향을 미치지 않지만, 중첩된 토플로지에 비해 호스트 개수가 두배나 필요하게 됩니다.&#x20;

{% hint style="info" %}
&#x20;외부 etcd 노드 토플로지로 HA 클러스터를 구성하기 위해서는 최소한 3개의 컨트롤 플레인과 3개의 etcd 노드가 필요합니다.
{% endhint %}

| 장점                                                | 단점                                              |
| ------------------------------------------------- | ----------------------------------------------- |
| **격리 및 안정성:** etcd와 컨트롤 플레인 컴포넌트를 분리하여 리소스 경쟁 최소화 | **구성 복잡도 증가:** etcd 전용 노드 운영·모니터링·백업까지 별도 관리 필요 |
| **성능 최적화:** etcd 전용 서버에 I/O 및 스토리지를 최적화 가능        | **더 많은 인프라 자원:** 노드 수와 관리 비용이 늘어남               |
| 장애가 한쪽(컨트롤 플레인 또는 etcd)에 발생해도 다른 쪽에 미치는 영향이 줄어듦   | kubeadm 등 설치 자동화 도구를 사용할 때 초기 설정이 stacked보다 복잡  |

<p align="center"><sup>[표] 외부 etcd 노드의 장단점</sup></p>

### 운영환경에서의 etcd

> 내구성과 고가용성을 위해 운영 환경에서 etcd를 다중 노드 클러스터로 실행하고 주기적으로 백업하세요. 운영 환경에서는 5개 노드로 구성된 클러스터를 사용하는 것이 좋습니다.

[공식문서](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/)에서는 운영 환경에서 5개 노드로 구성된 클러스터 사용을 권장합니다. 이는 이론적으로 클러스터 노드 수에는 하드 리밋이 없지만, 노드를 늘리면 합의 과정에서 모든 멤버에게 로그를 복제해야 하므로 쓰기 지연(latency)이 커지기 때문입니다. 즉, 노드가 많을수록 내결함성은 향상되지만, 더 많은 머신에 데이터를 복제해야 하므로 쓰기 성능은 떨어집니다.

* **2대까지 장애 허용**: Raft는 과반수 노드가 살아 있으면 합의를 유지할 수 있으므로, 5개 중 3개만 살아 있어도 정상 동작한다.
* **성능 저하 최소화**: 7개 이상으로 늘리면 장애 허용 범위가 조금 더 커지지만, 그만큼 쓰기 성능이 눈에 띄게 떨어진다.

결국 5\~7개 노드가 “내결함성과 성능 사이의 현실적 균형”을 이루는 sweet spot으로 평가되고, \
프로덕션 환경에서는 5노드 구성이 가장 널리 사용되고 안정성이 검증된 선택으로 여겨집니다.

{% hint style="info" %}
왜 노드를 홀수로하는 걸까요?

* Quorum은 **전체 노드 수의 과반수**가 필요합니다.
* 노드를 짝수로 두면, 예를 들어 4노드에서 2대가 고장 나면 남은 2대가 **과반수(3)** 를 충족하지 못해 **쓰기(Commit)가 불가능**합니다.
* 3, 5, 7처럼 홀수로 두면, 장애 허용 범위가 같은 조건에서 **필요한 노드 수도 최소화**됩니다.

자세한 내용은 [etcd 공식 문서](https://etcd.io/docs/v3.7/faq/#what-is-failure-tolerance)를 참고바랍니다.
{% endhint %}

